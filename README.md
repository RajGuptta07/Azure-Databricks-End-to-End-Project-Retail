# Azure-Databricks-End-to-End-Project-Retail

# Project Overview:

Built an end to end retail data pipeline using Azure Data Factory, Databricks, and ADLS Gen2 with GitHub integration. Implemented Bronzeâ€“Silverâ€“Gold architecture with PySpark transformations, SCD Type 1 & 2, and a Star Schema to deliver analytics-ready data models

# Project Architecture
![Architecture Diagram](Retail_Project_Architecture.png)


# ğŸ“‚ Project Structure

```
Azure-Databricks-End-to-End-Project-Retail/
â”‚â”€â”€ README.md                      # Project documentation and overview
â”‚â”€â”€ Retail_Project_Architecture.png # Architecture diagram of the pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ Azure_Databricks_Notebooks   # Databricks notebooks for each layer of the pipeline
â”‚   â”œâ”€â”€ parameter_config.ipynb          # Defines datasets (orders, customers, products)
â”‚   â”œâ”€â”€ Retail_Bronze_layer.ipynb       # Ingestion of raw data into Bronze layer
â”‚   â”œâ”€â”€ Retail_Silver_Customers.ipynb   # Customer data cleaning & transformation
â”‚   â”œâ”€â”€ Retail_Silver_Products.ipynb    # Product standardization & discount logic
â”‚   â”œâ”€â”€ Retail_Silver_Orders.ipynb      # Order enrichment (ranking, date features)
â”‚   â”œâ”€â”€ Retail_Silver_Regions.ipynb     # Regional data transformation
â”‚   â”œâ”€â”€ Retail_Gold_Customers.ipynb     # Gold layer SCD Type 1 (Customers)
â”‚   â”œâ”€â”€ Retail_Gold_Products.ipynb      # Gold layer SCD Type 2 (Products with DLT)
â”‚   â””â”€â”€ Retail_Gold_Orders.ipynb        # Fact Orders + Star Schema integration
â”‚
â”œâ”€â”€ ğŸ“‚ Data                        # Sample retail CSV datasets
â”‚   â”œâ”€â”€ customers-first.csv
â”‚   â”œâ”€â”€ customers-second.csv
â”‚   â”œâ”€â”€ orders-first.csv
â”‚   â”œâ”€â”€ orders-second.csv
â”‚   â”œâ”€â”€ products-first.csv
â”‚   â”œâ”€â”€ products-second.csv
â”‚   â””â”€â”€ regions.csv
â”‚
â”œâ”€â”€ ğŸ“‚ adf                         # Azure Data Factory configuration
â”‚   â”œâ”€â”€ ğŸ“‚ dataset                     # Dataset definitions (JSON)
â”‚   â”œâ”€â”€ ğŸ“‚ linkedService               # Linked service configurations (JSON)
â”‚   â””â”€â”€ ğŸ“‚ pipeline                    # Pipeline workflows (JSON)
```


# ğŸ›  Tech Stack & Tools

â˜ï¸**Cloud Platform**: Microsoft Azure  
ğŸ’¾**Data Storage**: Azure Data Lake Storage Gen2 (ADLS Gen2)  
ğŸ”„**Data Ingestion & Orchestration**: Azure Data Factory (ADF) â€“ Web, ForEach, If, Copy activities  
ğŸ› **Data Processing & Transformation**: Azure Databricks (with Unity Catalog)  
ğŸ“‚**File Formats**: CSV (raw data), Parquet (ingestion), Delta Lake (Bronze, Silver, Gold layers)  
ğŸ—„**Data Modeling**: Star Schema, SCD Type 1 (PySpark Merge), SCD Type 2 (Delta Live Tables)  
ğŸ**Programming Language**: PySpark (Python APIs for Spark)  
â±**Workflow Orchestration**: Databricks Jobs (parallel & sequential execution)  
ğŸ”§**Version Control**: Git & GitHub integration  
ğŸ“Š**Visualization**: Architecture Diagram (`Retail_Project_Architecture.png`)  
ğŸ’»**Development Environment**: VS Code, Databricks Notebooks  













